{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridging Perception and Reasoning to Build Interpretable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge in Perception\n",
    "\n",
    "I have previosly explored the way in which knowledge, understanding and explanation relate to each other. In this research project I'm curious as to how different artificial intelligence approaches relate to human cognitive processes. \n",
    "\n",
    "There is much confounding of intelligence and knowledge in the social science literature, however, [GREGORY1997KNOWLEDGE] attempts to separate the concepts: \n",
    "    ''more knowledge can reduce the need intelligence needed for solving problems''.\n",
    "    \n",
    "To me this is really interesting because it relates back to the argument against explainable AI presented by Cynthia Rudin: that we should focus our energy on extracting better knowledge from our data (or prior experience) instead of attempting to explain deep models. This is something I'm thinking about in other research projects LINK HERE.\n",
    "\n",
    "This research project focuses instead on perception and reasoning, how important these two tasks for human intelligence and how distinct they are. I want to apply these ideas to develop more human like artifical intelligence that is hopefully more interpetable. \n",
    "\n",
    "[GREGORY1997KNOWLEDGE] separates intelligence into two components:\n",
    "<ul>\n",
    "    <li> Kinetic intelligence: active processing of information </li>\n",
    "    <li> Potential intelligence: Stored from the past potential intelligence of knowledge that is selected and applied to current situation. </li> \n",
    "    </ul>\n",
    "  \n",
    "[GREGORY1997KNOWLEDGE] Knowledge is necesarry for vision because sensory information is inherently ambiguous, simialarly, errors of perception can be attributed to knowledge being misapplied. Some way of creating artifical potential intelligence is therefore necessary for AI to be considered more 'brain-like'. \n",
    " \n",
    "If reasoning is the human brain's capacity of making sense of things based on new or existing information then we can equate it to the way the brain balances kinetic and potential intelligence. This process can be explored a little better through considering the behaviour of the brain when presented with an optical illusion.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Illusions\n",
    "\n",
    "Optical illusions are images that confuse the brain. The types of optical illusions include:\n",
    "<ul> \n",
    "    <li> Literal optical illusion - when the image you see is different from the images that make it up </li>\n",
    "    <li> Physiological optical illusion: overstimulation of the brain's senses </li>\n",
    "<li> Cognitive optical illusions: how the subconscious mind thinks and how it relates one object to another </li>\n",
    "</ul>\n",
    "\n",
    "[GREGORY1997KNOWLEDGE] argues that <em> \"it is significant that illusions are experienced perceptually despite the observer knowing conceptually that these are illusory - even to the point of knowing the causes of the phenomena.\" </em> This seems to imply that conceptual and perceptual knowledge are independent but this is still a hotly debated subject within the psychological literature. \n",
    "    \n",
    "## Optical Illusions in Health\n",
    "\n",
    "When thinking about optical illusions in health we can consider diagnosis using radiography scans. Optical illusions are common in radiology. It is important to understand them because they can create the illusion of disease, leading to incorrect image interpretation [BUCKLE2013ILLUSIONS]. Optical illusions in radiography can be categorised based on the visual system that processes them: lower-order brain structures deal with illusions of sensation that are usually due to the brain processing light whereas higher order brain structures deal with illusions of perception that arise as the brain translates sensory input into mental images. \n",
    "\n",
    "### Illusions of Sensation \n",
    "\n",
    "Visual sensation denotes the process by which the brain converts light incidence on the retina into neural activity. The types of optical illusion that arise as a product of visual sensation are Mach bands and Background illusions. Mach bands are light or dark lines that occur at the boundary between objects with different opacity characteristics in an image. Mach bands occur really frequently in radiography (think about scans of bones and tissue) and make it really hard to identify anatomical boundaries. Background effect is caused by the grey level of an object's background. This type of illusion appears frequently in CT/MRI scans as an object in the foreground becomes less/more conspicuous as the grey level of its background is modulated.\n",
    "\n",
    "### Illusions of Perceptions\n",
    "\n",
    "As discussed above, perception is a fiercely debated topic within the cognitive science literature. However, it is widely acknowledged that it involves two processes: top down, whereby prior knoweldge (what we previously discussed as potential knowledge) shapes the perceptive process from the beginning and bottom-up, where the percpetion of an image is built modularly using sensory input and then incorporating potential knowledge. According to CITE HErE, percpetion begins with the bottom up processing of an image into features with the importance of each feature determined by top down processes. Together, top-down and bottom-up processes combine with prior experience to create a hypothesis about the image being viewed and form perception.\n",
    "\n",
    "Ambiguous figures are optical illusions that arise thanks to the multiple percpetual interpretations of the same image. They are common in radiography and which interpretation to go with is often heavily dependent on the experience of the doctor. Similarly, these optical illusions are heavily influenced by the choice of background and foreground. Fictional illusions, including subjective contours, questionable lesions, is where the mind perceives something that isnt actually there. Radiographs are the main source of subjective contours in medical imaging thanks to the imperfection of projecting a 3d anatomical structure onto a 2d film. Paradoxic Illusions are images that appear to be impossible, defying physical laws or rational thought.\n",
    "\n",
    "Understanding and recognising optical illusions in medical imagine is important for three reasons: 1) Unidentification of optical illusions can lead to mis-diagnosis 2) Identification of a particular optical illusion can actually aid a diagnosis 3) Optical illusions provide insight into the way in which perceptions and sensation influence vision. \n",
    "\n",
    "I think an interesting research area would be to build AI that could identify optical illusions in medical images. It is understood that AI is currently bad at recognising optical illusions, how we could build these types of models is therefore an open research area and is discussed in more detail below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Intelligence in AI\n",
    "\n",
    "We all know that machine learning is very good at mapping sensory content to a concept but we also all know that machine learning is NOT very good at learning simple relations or putting things into context. Siimilarly, AI is bad at recognising optical illusions.\n",
    "Why is this the case?\n",
    "\n",
    "[DAI2019BRIDGING] argues that ML is just curve fitting and has no explicit model of reasoning. I want to take this a bit further and explore how machine learning fits into kinetic or potential intelligence and how it fits into reasoning and perception.\n",
    "\n",
    "## Explainability's Dependence on Perception\n",
    "\n",
    "[DAI2019BRIDGING] argues that treat reason as perception is a very bad idea. I.e. trying to solve human recogniion in a pure perception framework, as demonstrated by THYS2019FOOLING who use advesarial images to trick the the perception based frameowrk into misclassification. Treating reason as perception also brings further problems\n",
    "<ul>\n",
    "    <li> 1) Hard to tell machines what we know (incoporate potential knowledge) </li>\n",
    "    <li> 2) Hard to understand how machines learn (interpretable AI) </li>\n",
    "    </ul>\n",
    "\n",
    "This argument against treating percpetion and reasoning as the same process within machine learning can also be appied to explainable AI. A significant number of current state-of-the-art in explainability techniques extract patterns in the sensory input and present these patterns as reasonings about the model's behaviour. Therefore, in the same way a perception based framework is fooled by advesarial examples, an explainability framework can also be fooled. This has been exposed and discussed extensively in the literature.  \n",
    "\n",
    "[DAI2019BRIDGING] argues that the real research gap lies in trying to work out how to combine artifical reasoning with artificial perception. I argue that this research gap could also be the way forward for interpretable machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Can Reasoning Bring\n",
    "\n",
    "What is reasoning in artifical intelligence?\n",
    "\n",
    "Machine reasoning was the first task in AI and was then developed as symbolic AI including,\n",
    "inductive logic programming, probabilistic logic programming, constraint logic programming. These sorts of symbolic systems were, at the time, claimed to have \"the necessary and sufficient means for general intelligent action\" by â€‰Allen Newell and Herbert A. Simon. Since, symbolic AI has become increasingly unpopular thanks to the requirement that they be hard coded, the rise of machine learning and claims by computer scientists such as Stuart Russel advising that \"symbols dont exist\" in nature.\n",
    "\n",
    "## Perception and Reasoning in Biomedical Data\n",
    "\n",
    "Depsite its popularity, deep learning has a tendency to overfit which is often coutracted by seeking more training data. However, this approach is often not possible, particularly in domains such as health where vast amounts of quality data isn't easily availavle. More recently, therefore , attention has returned in part to symbolic approaches who are extremely data efficient, but cant be applied to ambiguous data types like images. There is now therefore a concentrated effort to bridge symbolic and machine learning approaches. These include connectionist networks. We review two excting hybrid state-of-the-art approaches below.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art\n",
    "\n",
    "### [DAI2019BRIDGING]\n",
    "\n",
    "In this paper, Dai et al. use abductive learning to bridge perception based and reasoning based modules to recognise numbers and resolve unknown mathematical operations simultaneously from images of simple\n",
    "hand-written equations.\n",
    "\n",
    "The framework as presented by Dai et al. uses machine learning to predict pseudo-labels for the possible concepts for the training data. The abductive module then uses the generate pseduo labels for the observations and background knowledge, transformed into a symbolic system to abduce a set of hypotheses that explain the observed facts. Dai et al. transform the hybrid framework into an optimatisation problem where the objective is to maximise the consistency of the background knoweledge with the training examples.  \n",
    "\n",
    "### [EVANS2018LEARNING]\n",
    "\n",
    "In this paper, Evans et al. present a differentiable inductive logic framework that is trained via back propagation via a likelihood obective function. Evans et. al transform the ILP problem into a SAT problem and then use probability measure to transform the dicrete feature flags into differentiable continuous values. The authors report sucess on non-complex prediction tasks but note the large amount of memory needed by their framework which limits the complexity of task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to explainability of biomedical data and what i want to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<ul> \n",
    "    <li> [GREGORY1997KNOWLEDGE] Gregory, Richard L. \"Knowledge in perception and illusion.\" Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences 352.1358 (1997): 1121-1127. </li>\n",
    "    <li> [BUCKLE2013ILLUSIONS] Buckle, Christopher E., Viyan Udawatta, and Christopher M. Straus. \"Now you see it, now you donâ€™t: visual illusions in radiology.\" Radiographics 33.7 (2013): 2087-2102. </li>\n",
    "    <li> [GEGORY1968PECPTUAL] Gregory, Richard Langton. \"Perceptual illusions and brain models.\" Proceedings of the Royal Society of London. Series B. Biological Sciences 171.1024 (1968): 279-296. </li>\n",
    "      <li> [KOMPRIDIS2000REASON] Kompridis, Nikolas (2000). \"So We Need Something Else for Reason to Mean\". International Journal of Philosophical Studies. 8 (3): 271â€“295. doi:10.1080/096725500750039282. </li>\n",
    "    <li> https://www.cleareyes.com/eye-care-blog/201610/types-optical-illusions/#:~:text=There%20are%20three%20main%20types,%E2%80%9Ctrick%E2%80%9D%20of%20the%20eye. </li>\n",
    "    <li> [DAI2019BRIDGING] Dai, Wang-Zhou, et al. \"Bridging machine learning and logical reasoning by abductive learning.\" Advances in Neural Information Processing Systems. 2019. </li>\n",
    "    <li> [THYS2019FOOLING] Thys, Simen, Wiebe Van Ranst, and Toon GoedemÃ©. \"Fooling automated surveillance cameras: adversarial patches to attack person detection.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 2019. </li>\n",
    "    <li> [EVANS2018LEARNING] Evans, Richard, and Edward Grefenstette. \"Learning explanatory rules from noisy data.\" Journal of Artificial Intelligence Research 61 (2018): 1-64. </li> \n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
